{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3246da-b5f4-45e1-9aad-56772bff032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "sys.path.append('../../..')\n",
    "from hydradx.model.processing import query_sqlPad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2585953b-2472-4b7b-9547-78a9f95499d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 10000\n",
    "chunks_per_file = 100\n",
    "\n",
    "def check_errors(all_data):\n",
    "    errors = []\n",
    "    for i in range(int(len(all_data) / chunk_size)):\n",
    "        correctIndex = (i + len(errors)) * chunk_size\n",
    "        if correctIndex >= len(all_data):\n",
    "            break\n",
    "        if all_data[i * chunk_size][0] != correctIndex:\n",
    "            errors.append(i)\n",
    "    return errors\n",
    "\n",
    "\n",
    "async def add_data(position: int, all_data: list):\n",
    "    query = (\n",
    "        f\"with hdx_changes as (\"\n",
    "        f\"  select\"\n",
    "        f\"    block_id,\"\n",
    "        f\"    '0' as asset_id,\"\n",
    "        f\"    (args->>'amount')::numeric as amount\"\n",
    "        f\"  from event\"\n",
    "        f\"  where\"\n",
    "        f\"    name like 'Balances.Transfer'\"\n",
    "        f\"    and args->>'to' = '0x6d6f646c6f6d6e69706f6f6c0000000000000000000000000000000000000000'\"\n",
    "        f\"  union all\"\n",
    "        f\"  select\"\n",
    "        f\"    block_id,\"\n",
    "        f\"    '0' as asset_id,\"\n",
    "        f\"    -(args->>'amount')::numeric as amount\"\n",
    "        f\"  from event\"\n",
    "        f\"  where\"\n",
    "        f\"    name like 'Balances.Transfer'\"\n",
    "        f\"    and args->>'from' = '0x6d6f646c6f6d6e69706f6f6c0000000000000000000000000000000000000000'\"\n",
    "        f\"),\"\n",
    "        f\"tokens_changes as (\"\n",
    "        f\"  select\"\n",
    "        f\"    block_id,\"\n",
    "        f\"    args->>'currencyId' as asset_id,\"\n",
    "        f\"    (args->>'amount')::numeric as amount\"\n",
    "        f\"  from event\"\n",
    "        f\"  where\"\n",
    "        f\"    name = 'Tokens.Transfer'\"\n",
    "        f\"    and args->>'to' = '0x6d6f646c6f6d6e69706f6f6c0000000000000000000000000000000000000000'\"\n",
    "        f\"  union all\"\n",
    "        f\"  select\"\n",
    "        f\"    block_id,\"\n",
    "        f\"    args->>'currencyId' as asset_id,\"\n",
    "        f\"    -(args->>'amount')::numeric as amount\"\n",
    "        f\"  from event\"\n",
    "        f\"  where\"\n",
    "        f\"    name = 'Tokens.Transfer'\"\n",
    "        f\"    and args->>'from' = '0x6d6f646c6f6d6e69706f6f6c0000000000000000000000000000000000000000'\"\n",
    "        f\"  union all\"\n",
    "        f\"  select\"\n",
    "        f\"    block_id,\"\n",
    "        f\"    args->>'currencyId' as asset_id,\"\n",
    "        f\"    (args->>'amount')::numeric as amount\"\n",
    "        f\"  from event\"\n",
    "        f\"  where\"\n",
    "        f\"    name = 'Tokens.Deposited'\"\n",
    "        f\"    and args->>'who' = '0x6d6f646c6f6d6e69706f6f6c0000000000000000000000000000000000000000'\"\n",
    "        f\"  union all\"\n",
    "        f\"  select\"\n",
    "        f\"    block_id,\"\n",
    "        f\"    args->>'currencyId' as asset_id,\"\n",
    "        f\"    -(args->>'amount')::numeric as amount\"\n",
    "        f\"  from event\"\n",
    "        f\"  where\"\n",
    "        f\"    name = 'Tokens.Withdrawn'\"\n",
    "        f\"    and args->>'who' = '0x6d6f646c6f6d6e69706f6f6c0000000000000000000000000000000000000000'\"\n",
    "        f\"),\"\n",
    "        f\"balance_changes as (\"\n",
    "        f\"  select * from hdx_changes\"\n",
    "        f\"  union all\"\n",
    "        f\"  select * from tokens_changes\"\n",
    "        f\"),\"\n",
    "        f\"balance_history as (\"\n",
    "        f\"  select\"\n",
    "        f\"    height,\"\n",
    "        f\"    timestamp,\"\n",
    "        f\"    block_id,\"\n",
    "        f\"    asset_id,\"\n",
    "        f\"    symbol,\"\n",
    "        f\"    sum(amount) over (partition by asset_id order by block_id) / 10 ^ decimals as balance\"\n",
    "        f\"  from balance_changes\"\n",
    "        f\"  inner join block on block_id = block.id\"\n",
    "        f\"  inner join token_metadata on asset_id = token_metadata.id::text\"\n",
    "        f\")\"\n",
    "        f\"select timestamp, symbol, balance as liquidity \"\n",
    "        f\"from balance_history \"\n",
    "        f\"order by timestamp asc \"\n",
    "        f\"limit {chunk_size} offset {chunk_size} * {position}\"\n",
    "    )\n",
    "    new_data = await query_sqlPad(query)\n",
    "    new_data = [[position * chunk_size + i] + new_data[i] for i in range(len(new_data))]\n",
    "    # insert at the correct position\n",
    "    all_data = all_data[:position * chunk_size] + new_data + all_data[position * chunk_size:]\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def load_history_file(filename: str):\n",
    "    with open(f'./data/{filename}', 'r') as file:\n",
    "        file_data = json.loads('[' + file.read() + ']')\n",
    "        index = file_data[-1][0]\n",
    "    return file_data\n",
    "\n",
    "\n",
    "def save_history_file(all_data: list, n: int):\n",
    "    filename = f'./data/omnipool_history_{str(n).zfill(2)}'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(', '.join([json.dumps(line) for line in all_data[chunk_size * chunks_per_file * (n - 1): chunk_size * chunks_per_file * n]]))\n",
    "    print(f'Saved {filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2078da79-874e-4d0e-9e57-4fc7210e7ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading omnipool_history_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jepid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:353: RuntimeWarning: coroutine 'add_data' was never awaited\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading omnipool_history_02\n",
      "loading omnipool_history_03\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "n = 0\n",
    "file_ls = os.listdir('./data')\n",
    "for filename in file_ls:\n",
    "    if filename.startswith('omnipool_history'):\n",
    "        print(f'loading {filename}')\n",
    "        all_data += load_history_file(filename)\n",
    "\n",
    "async def fix_errors(all_data):\n",
    "    # error checking and correction\n",
    "    # this works in the specific case where a piece of chunk_size length failed to download, which is typical\n",
    "    # other types of errors would require different handling\n",
    "    errors = check_errors(all_data)\n",
    "    while errors:\n",
    "        errors = check_errors(all_data)\n",
    "        print(f'Detected error at: {errors[0]}')\n",
    "        all_data = await add_data(position=error, all_data=all_data)\n",
    "    else:\n",
    "        print('Data looks error-free.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2645827-6efb-4574-89e6-5a0cca2726fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data looks error-free.\n",
      "saving omnipool_history_04\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'coroutine' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     all_data \u001b[38;5;241m=\u001b[39m add_data(position\u001b[38;5;241m=\u001b[39mn, all_data\u001b[38;5;241m=\u001b[39mall_data)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaving omnipool_history_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(file_number)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m save_history_file(all_data, file_number)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_data) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_data) \u001b[38;5;241m%\u001b[39m chunk_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# probably means we're finished. There might be a better way to detect this but I think it'll do\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36msave_history_file\u001b[1;34m(all_data, n)\u001b[0m\n\u001b[0;32m    110\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/omnipool_history_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(n)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m--> 112\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([json\u001b[38;5;241m.\u001b[39mdumps(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunks_per_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunks_per_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m]))\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'coroutine' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# this doesn't exactly work right. \n",
    "# It loads what's there correctly, but fails to stop when it gets to the end of the data, and creats an extra (blank) history file.\n",
    "\n",
    "while True:\n",
    "    await fix_errors(all_data)\n",
    "    file_number = round(len(all_data) / chunk_size / chunks_per_file) + 1\n",
    "    new_data = []\n",
    "    start_at = round(len(all_data) / chunk_size)\n",
    "    for n in range(start_at, start_at + chunks_per_file):\n",
    "        all_data = add_data(position=n, all_data=all_data)\n",
    "    print(f'saving omnipool_history_{str(file_number).zfill(2)}')\n",
    "    save_history_file(all_data, file_number)\n",
    "    if all_data[-1][0] == len(all_data) - 1 and len(all_data) % chunk_size != 0:\n",
    "        # probably means we're finished. There might be a better way to detect this but I think it'll do\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2907a-e5b2-4d71-b8e4-b5574d62f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[-1][0], len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45556f1-e7f3-4479-961b-4bb868ac8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data) / chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee398d3c-0628-4bdb-8746-5c4dd47ec27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_history_file(all_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ae068-b091-49bf-ab81-75a420ec8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "balances = {}\n",
    "for line in all_data:\n",
    "    symbol = line[1]\n",
    "    if symbol not in balances:\n",
    "        balances[symbol] = {}\n",
    "    balances[symbol][line[0]] = line[-1]\n",
    "for symbol in balances:\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(balances[symbol].keys(), balances[symbol].values())\n",
    "    plt.title(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04696340-b655-45a0-8e5e-a24db3d89796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada23be6-0a87-4001-aff2-2c0a4f29d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74f300-aa9d-4e6b-959a-298e63075f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6f1fb-ca1c-4f01-881c-721b937b92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "[symbol for symbol in balances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8ee967-8b57-4ec6-b581-7aa4ee49e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb398498-780b-425f-b87b-3722cf9d2b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93cdab7-67b0-4ef1-9f46-5ef504d9e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(all_data[9990:10010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381335b-bbee-4d41-b576-ec7c5bec47ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
